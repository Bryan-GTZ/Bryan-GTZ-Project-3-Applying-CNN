{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "DATA_DIR = \"/Users/bryangutierrez/Desktop/project3_ML\"   \n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 1e-4\n",
    "VAL_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "GROUP_NUMBER = 16  \n",
    "MODEL_PATH = f\"Group_{GROUP_NUMBER}_CNN_FullModel.ph\"\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Validation transformations\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['not_official', 'official']\n",
      "Total images: 25\n",
      "Train size: 20, Val size: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the full dataset\n",
    "full_dataset = datasets.ImageFolder(root=DATA_DIR, transform=train_transform)\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "print(\"Classes:\", class_names)  \n",
    "\n",
    "# Train/val split\n",
    "dataset_size = len(full_dataset)\n",
    "val_size = int(VAL_SPLIT * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_SEED)\n",
    ")\n",
    "\n",
    "# Update transforms for validation dataset\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Total images: {dataset_size}\")\n",
    "print(f\"Train size: {train_size}, Val size: {val_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RazorbackCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): AdaptiveAvgPool2d(output_size=(4, 4))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "class RazorbackCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A small CNN for binary classification (official vs not official).\n",
    "    Input: 3 x 500 x 500 images\n",
    "    Output: 2 logits (for classes 0 and 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(RazorbackCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 500 -> 250\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 250 -> 125\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 125 -> 62/63\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # ~62 -> ~31\n",
    "\n",
    "           \n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)  # 2 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = RazorbackCNN(num_classes=2).to(device)\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels).item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_corrects / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_corrects / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Train Loss: 0.6916 | Train Acc: 0.6000 || Val Loss: 0.6929 | Val Acc: 0.6000\n",
      "Epoch [2/15] Train Loss: 0.6804 | Train Acc: 0.6500 || Val Loss: 0.6921 | Val Acc: 0.6000\n",
      "Epoch [3/15] Train Loss: 0.6913 | Train Acc: 0.6000 || Val Loss: 0.6914 | Val Acc: 0.6000\n",
      "Epoch [4/15] Train Loss: 0.6721 | Train Acc: 0.6000 || Val Loss: 0.6927 | Val Acc: 0.6000\n",
      "Epoch [5/15] Train Loss: 0.6720 | Train Acc: 0.6000 || Val Loss: 0.6949 | Val Acc: 0.6000\n",
      "Epoch [6/15] Train Loss: 0.6488 | Train Acc: 0.6000 || Val Loss: 0.6994 | Val Acc: 0.6000\n",
      "Epoch [7/15] Train Loss: 0.6640 | Train Acc: 0.6000 || Val Loss: 0.7077 | Val Acc: 0.6000\n",
      "Epoch [8/15] Train Loss: 0.6579 | Train Acc: 0.6000 || Val Loss: 0.7203 | Val Acc: 0.6000\n",
      "Epoch [9/15] Train Loss: 0.6461 | Train Acc: 0.6000 || Val Loss: 0.7355 | Val Acc: 0.6000\n",
      "Epoch [10/15] Train Loss: 0.6370 | Train Acc: 0.6000 || Val Loss: 0.7493 | Val Acc: 0.6000\n",
      "Epoch [11/15] Train Loss: 0.6243 | Train Acc: 0.6000 || Val Loss: 0.7633 | Val Acc: 0.6000\n",
      "Epoch [12/15] Train Loss: 0.6250 | Train Acc: 0.6000 || Val Loss: 0.7816 | Val Acc: 0.6000\n",
      "Epoch [13/15] Train Loss: 0.6308 | Train Acc: 0.6000 || Val Loss: 0.7921 | Val Acc: 0.6000\n",
      "Epoch [14/15] Train Loss: 0.6112 | Train Acc: 0.6000 || Val Loss: 0.8100 | Val Acc: 0.6000\n",
      "Epoch [15/15] Train Loss: 0.6193 | Train Acc: 0.6000 || Val Loss: 0.8265 | Val Acc: 0.6000\n",
      "\n",
      "Best validation accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "          f\"|| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Load best model state\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "File Group_16_CNN_FullModel.ph cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 8. Save Full Model (for Blackboard)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Instructor said: save full model as Group_#_CNN_FullModel.ph\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# This saves the entire model object, not just the state_dict.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model, MODEL_PATH)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved full model to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: File Group_16_CNN_FullModel.ph cannot be opened."
     ]
    }
   ],
   "source": [
    "# Save the full model\n",
    "torch.save(model, MODEL_PATH)\n",
    "print(f\"Saved full model to: {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
